{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01213058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:39:28.568197Z",
     "iopub.status.busy": "2024-04-29T18:39:28.567481Z",
     "iopub.status.idle": "2024-04-29T18:39:41.470194Z",
     "shell.execute_reply": "2024-04-29T18:39:41.468849Z"
    },
    "papermill": {
     "duration": 12.914696,
     "end_time": "2024-04-29T18:39:41.473365",
     "exception": false,
     "start_time": "2024-04-29T18:39:28.558669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import punctuation, printable\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34836a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:39:41.488799Z",
     "iopub.status.busy": "2024-04-29T18:39:41.488130Z",
     "iopub.status.idle": "2024-04-29T18:40:24.446879Z",
     "shell.execute_reply": "2024-04-29T18:40:24.445194Z"
    },
    "papermill": {
     "duration": 42.970553,
     "end_time": "2024-04-29T18:40:24.450646",
     "exception": false,
     "start_time": "2024-04-29T18:39:41.480093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pyspellchecker-0.8.1-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.8.1\r\n"
     ]
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "copy_tree('/kaggle/input/spellchecker', '/kaggle/working/')\n",
    "\n",
    "!gzip '/kaggle/working/spellchecker/resources/en.json'\n",
    "\n",
    "!pip install '/kaggle/working/pyspellchecker-0.8.1-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728e82c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:40:24.469627Z",
     "iopub.status.busy": "2024-04-29T18:40:24.469062Z",
     "iopub.status.idle": "2024-04-29T18:40:24.733335Z",
     "shell.execute_reply": "2024-04-29T18:40:24.732288Z"
    },
    "papermill": {
     "duration": 0.277968,
     "end_time": "2024-04-29T18:40:24.736271",
     "exception": false,
     "start_time": "2024-04-29T18:40:24.458303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5ab10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:40:24.753004Z",
     "iopub.status.busy": "2024-04-29T18:40:24.752235Z",
     "iopub.status.idle": "2024-04-29T18:40:27.603649Z",
     "shell.execute_reply": "2024-04-29T18:40:27.602635Z"
    },
    "papermill": {
     "duration": 2.862703,
     "end_time": "2024-04-29T18:40:27.606347",
     "exception": false,
     "start_time": "2024-04-29T18:40:24.743644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17307, 3) (3, 2) (13125, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>bb4c434</td>\n",
       "      <td>People tend to use there cars so much, they ba...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>44e88b0</td>\n",
       "      <td>Imagine being a top scientist at NASA and Viki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0ba78ec</td>\n",
       "      <td>The face of Mars could not be created by alien...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>f96c287</td>\n",
       "      <td>Many people belive that the face on Mars was c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>317173f</td>\n",
       "      <td>Driverless Cars are coming soon or later? Peop...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "12696  bb4c434  People tend to use there cars so much, they ba...      3\n",
       "4625   44e88b0  Imagine being a top scientist at NASA and Viki...      3\n",
       "733    0ba78ec  The face of Mars could not be created by alien...      3\n",
       "16885  f96c287  Many people belive that the face on Mars was c...      3\n",
       "3334   317173f  Driverless Cars are coming soon or later? Peop...      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2\"\n",
    "train_data = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n",
    "extra_data = pd.read_csv('/kaggle/input/persaude-corpus-2/persuade_2.0_human_scores_demo_id_github.csv')\n",
    "\n",
    "extra_data = extra_data.rename(columns={'essay_id_comp': 'essay_id',\n",
    "                                        'holistic_essay_score': 'score'})\n",
    "extra_data = extra_data[['essay_id', 'full_text', 'score']]\n",
    "\n",
    "extra_data = extra_data[~extra_data['full_text'].isin(train_data['full_text'])]\n",
    "\n",
    "print(train_data.shape, test_data.shape, extra_data.shape)\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056028b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:40:27.623231Z",
     "iopub.status.busy": "2024-04-29T18:40:27.622489Z",
     "iopub.status.idle": "2024-04-29T19:54:52.083577Z",
     "shell.execute_reply": "2024-04-29T19:54:52.082065Z"
    },
    "papermill": {
     "duration": 4464.473005,
     "end_time": "2024-04-29T19:54:52.086844",
     "exception": false,
     "start_time": "2024-04-29T18:40:27.613839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_misspelled(words):\n",
    "    words = [word for word in words if word.strip()]\n",
    "\n",
    "    words = set(words) - {\"'s\", \"n't\"} - set(punctuation)\n",
    "\n",
    "    return spell.unknown(words)\n",
    "\n",
    "\n",
    "def get_sentences(text: str):\n",
    "    text = \"\".join(filter(lambda x: x in printable, text)).strip()\n",
    "    doc = nlp(text)\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = \"\".join(filter(lambda x: x in printable, text)).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_features(data_df: pd.DataFrame, output_dir='./output/data_features.csv', save=True):\n",
    "    data_df['full_text'] = data_df['full_text'].apply(preprocess_text)\n",
    "\n",
    "    # parse the text into paragraphs\n",
    "    data_df['paragraphs'] = data_df['full_text'].apply(lambda x: x.split(\"\\n\\n\"))\n",
    "    data_df['num_paragraphs'] = data_df['paragraphs'].apply(len)\n",
    "\n",
    "    # into sentences\n",
    "    data_df['sentences'] = data_df['full_text'].apply(get_sentences)\n",
    "    data_df['num_sentences'] = data_df['sentences'].apply(len)\n",
    "\n",
    "    # Create lists to hold the results\n",
    "    words = []\n",
    "    lemmas = []\n",
    "    pos = []\n",
    "    is_stop_word = []\n",
    "\n",
    "    # Process the texts in batches\n",
    "    for i, doc in enumerate(nlp.pipe(data_df['full_text'], batch_size=50)):\n",
    "        print(f\"Processing batch {i+1}/{len(data_df)}\", end=\"\\r\")\n",
    "\n",
    "        words.append([token.text for token in doc])\n",
    "        lemmas.append([token.lemma_ for token in doc])\n",
    "        pos.append([token.pos_ for token in doc])\n",
    "        is_stop_word.append([token.is_stop for token in doc])\n",
    "\n",
    "    data_df['words'] = words\n",
    "    data_df['lemma'] = lemmas\n",
    "    data_df['pos'] = pos\n",
    "    data_df['is_stop_word'] = is_stop_word\n",
    "\n",
    "    data_df['num_words'] = data_df['words'].apply(len)\n",
    "\n",
    "    data_df['num_conjunctions'] = data_df['pos'].apply(\n",
    "        lambda x: len([pos for pos in x if pos == 'CCONJ']))\n",
    "\n",
    "    data_df['num_distinct_words'] = data_df['lemma'].apply(\n",
    "        lambda x: len(set(x)))\n",
    "\n",
    "    data_df['num_misspell'] = data_df['lemma'].apply(count_misspelled)\n",
    "    data_df['num_misspell'] = data_df['num_misspell'].apply(len)\n",
    "\n",
    "    data_df['mean_word_len'] = data_df['lemma'].apply(lambda x: np.mean(\n",
    "        [len(word) for word in x if word.strip() and word not in punctuation]))\n",
    "\n",
    "    data_df['mean_sent_len'] = data_df['sentences'].apply(\n",
    "        lambda x: np.mean([len([token.text for token in sent]) for sent in x]))\n",
    "\n",
    "    if save:\n",
    "        data_df.to_csv(output_dir, index=False)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "train_data = get_features(train_data)\n",
    "test_data = get_features(test_data)\n",
    "extra_data = get_features(extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557f682d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:54:52.105076Z",
     "iopub.status.busy": "2024-04-29T19:54:52.104625Z",
     "iopub.status.idle": "2024-04-29T19:54:52.210110Z",
     "shell.execute_reply": "2024-04-29T19:54:52.208691Z"
    },
    "papermill": {
     "duration": 0.117034,
     "end_time": "2024-04-29T19:54:52.212747",
     "exception": false,
     "start_time": "2024-04-29T19:54:52.095713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24345, 20) (6087, 20) (3, 19)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([train_data, extra_data], ignore_index=True)\n",
    "# shuffle the data\n",
    "all_data = all_data.sample(frac=1, random_state=random_seed)\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "train_ratio, val_ratio = 0.8, 0.2\n",
    "\n",
    "train_df= all_data.iloc[:int(train_ratio*len(all_data))]\n",
    "val_df = all_data.iloc[int(train_ratio*len(all_data)):]\n",
    "test_df = test_data\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994ebf90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:54:52.229725Z",
     "iopub.status.busy": "2024-04-29T19:54:52.229263Z",
     "iopub.status.idle": "2024-04-29T19:55:00.586385Z",
     "shell.execute_reply": "2024-04-29T19:55:00.585013Z"
    },
    "papermill": {
     "duration": 8.369653,
     "end_time": "2024-04-29T19:55:00.589811",
     "exception": false,
     "start_time": "2024-04-29T19:54:52.220158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_path = '/kaggle/input/essay-scoring-models/longformer-base-4096'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "embedder = AutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b10c44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:55:00.608360Z",
     "iopub.status.busy": "2024-04-29T19:55:00.606937Z",
     "iopub.status.idle": "2024-04-29T19:55:00.615131Z",
     "shell.execute_reply": "2024-04-29T19:55:00.614011Z"
    },
    "papermill": {
     "duration": 0.020115,
     "end_time": "2024-04-29T19:55:00.618152",
     "exception": false,
     "start_time": "2024-04-29T19:55:00.598037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ling_features = ['num_paragraphs', 'num_words', 'num_conjunctions',\n",
    "                 'num_distinct_words', 'num_misspell',\n",
    "                 'mean_word_len', 'num_sentences', 'mean_sent_len']\n",
    "\n",
    "hyperparameters = {\n",
    "    'lr': 1e-5,\n",
    "    'dropout': 0.25,\n",
    "    'epochs': 3,\n",
    "    'batch_size': 40,\n",
    "    'max_seq_len': 4096,\n",
    "    'ling_features_hidden_size': 128,\n",
    "    'embedding_model': model_path,\n",
    "    'train_set': {\n",
    "        'total': len(train_df),\n",
    "        'ratio': train_ratio,\n",
    "    },\n",
    "    'val_set': {\n",
    "        'total': len(val_df),\n",
    "        'ratio': val_ratio,\n",
    "    },\n",
    "    'test_set': {\n",
    "        'total': len(test_df),\n",
    "    },\n",
    "    'linguistic_features': ling_features,\n",
    "    'accelator': str(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenizer(train_df['full_text'].tolist(),\n",
    "                            max_length=hyperparameters['max_seq_len'],\n",
    "                            padding='max_length', truncation=True, \n",
    "                            return_tensors=\"np\")\n",
    "\n",
    "train_df['input_ids'] = train_tokenized['input_ids'].tolist()\n",
    "train_df['attention_mask'] = train_tokenized['attention_mask'].tolist()\n",
    "\n",
    "\n",
    "print(len(train_df.sample(1).iloc[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tokenized = tokenizer(val_df['full_text'].tolist(),\n",
    "                          max_length=hyperparameters['max_seq_len'],\n",
    "                          padding='max_length', truncation=True, \n",
    "                          return_tensors=\"np\")\n",
    "\n",
    "val_df['input_ids'] = val_tokenized['input_ids'].tolist()\n",
    "val_df['attention_mask'] = val_tokenized['attention_mask'].tolist()\n",
    "\n",
    "\n",
    "print(len(val_df.sample(1).iloc[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8c2f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:55:00.635595Z",
     "iopub.status.busy": "2024-04-29T19:55:00.634464Z",
     "iopub.status.idle": "2024-04-29T19:56:01.964353Z",
     "shell.execute_reply": "2024-04-29T19:56:01.963102Z"
    },
    "papermill": {
     "duration": 61.341732,
     "end_time": "2024-04-29T19:56:01.967305",
     "exception": false,
     "start_time": "2024-04-29T19:55:00.625573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3159259489.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['input_ids'] = train_tokenized['input_ids'].tolist()\n",
      "/tmp/ipykernel_18/3159259489.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['attention_mask'] = train_tokenized['attention_mask'].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560\n",
      "2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3159259489.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df['input_ids'] = val_tokenized['input_ids'].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560\n",
      "2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3159259489.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df['attention_mask'] = val_tokenized['attention_mask'].tolist()\n"
     ]
    }
   ],
   "source": [
    "test_tokenized = tokenizer(test_df['full_text'].tolist(),\n",
    "                           max_length=hyperparameters['max_seq_len'], \n",
    "                           padding='max_length', truncation=True, \n",
    "                           return_tensors=\"np\")\n",
    "\n",
    "test_df['input_ids'] = test_tokenized['input_ids'].tolist()\n",
    "test_df['attention_mask'] = test_tokenized['attention_mask'].tolist()\n",
    "\n",
    "print(len(test_df.sample(1).iloc[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3a085f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:56:01.987287Z",
     "iopub.status.busy": "2024-04-29T19:56:01.985973Z",
     "iopub.status.idle": "2024-04-29T19:56:02.002766Z",
     "shell.execute_reply": "2024-04-29T19:56:02.001520Z"
    },
    "papermill": {
     "duration": 0.030191,
     "end_time": "2024-04-29T19:56:02.005587",
     "exception": false,
     "start_time": "2024-04-29T19:56:01.975396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiFeaturesDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        # self.text = df['clean_text'].values\n",
    "        self.token_ids = df['input_ids'].values\n",
    "        self.attention_mask = df['attention_mask'].values\n",
    "        self.score = df['score'].values\n",
    "        self.ling_features = []\n",
    "        for feature in ling_features:\n",
    "            self.ling_features.append(df[feature].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.score)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = []\n",
    "        for feature in self.ling_features:\n",
    "            features.append(feature[idx])\n",
    "\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "        score = torch.reshape(torch.tensor(\n",
    "            self.score[idx], dtype=torch.float), (1,))\n",
    "\n",
    "        return torch.tensor(self.token_ids[idx]), torch.tensor(self.attention_mask[idx]), features, score\n",
    "\n",
    "\n",
    "train_dataset = MultiFeaturesDataset(train_df)\n",
    "val_dataset = MultiFeaturesDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0499f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:56:02.024235Z",
     "iopub.status.busy": "2024-04-29T19:56:02.023810Z",
     "iopub.status.idle": "2024-04-29T19:56:02.150848Z",
     "shell.execute_reply": "2024-04-29T19:56:02.149647Z"
    },
    "papermill": {
     "duration": 0.139393,
     "end_time": "2024-04-29T19:56:02.153547",
     "exception": false,
     "start_time": "2024-04-29T19:56:02.014154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 2560]) torch.Size([40, 2560]) torch.Size([40, 11]) torch.Size([40, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n",
    "\n",
    "for token_ids, attention_mask, features, score in train_dataloader:\n",
    "    print(token_ids.shape, attention_mask.shape, features.shape, score.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba9dca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:56:02.174051Z",
     "iopub.status.busy": "2024-04-29T19:56:02.173044Z",
     "iopub.status.idle": "2024-04-29T19:56:08.815508Z",
     "shell.execute_reply": "2024-04-29T19:56:08.814072Z"
    },
    "papermill": {
     "duration": 6.656594,
     "end_time": "2024-04-29T19:56:08.818710",
     "exception": false,
     "start_time": "2024-04-29T19:56:02.162116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiFeaturesModel(torch.nn.Module):\n",
    "    def __init__(self, embedder,\n",
    "                 lf_input_size, lf_hidden_size=64,\n",
    "                 dropout=0.2):\n",
    "        super(MultiFeaturesModel, self).__init__()\n",
    "        # freeze\n",
    "        for param in embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.embedder = embedder\n",
    "        self.lf = torch.nn.Linear(lf_input_size,\n",
    "                                  lf_hidden_size)\n",
    "        self.fc = torch.nn.Linear(\n",
    "            lf_hidden_size + embedder.config.hidden_size, 128)\n",
    "        self.regressor = torch.nn.Linear(128, 1)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, token_ids, attention_mask, ling_features):\n",
    "        embedded = self.embedder(token_ids,\n",
    "                                 attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        if self.training:\n",
    "            embedded = self.dropout(embedded)\n",
    "        ling_features = F.leaky_relu(self.lf(ling_features))\n",
    "        if self.training:\n",
    "            ling_features = self.dropout(ling_features)\n",
    "        features = torch.cat((embedded, ling_features), dim=1)\n",
    "        features = F.leaky_relu(self.fc(features))\n",
    "        if self.training:\n",
    "            features = self.dropout(features)\n",
    "        score = self.regressor(features)\n",
    "        return score\n",
    "\n",
    "\n",
    "model = MultiFeaturesModel(embedder, len(ling_features),\n",
    "                           hyperparameters['ling_features_hidden_size'],\n",
    "                           hyperparameters['dropout'])\n",
    "\n",
    "model.load_state_dict(torch.load('/kaggle/input/essay-scoring-models/checkpoints/multi_features_longformer-base-4096_model_2024-04-29_10-26.pth',\n",
    "                                 map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f687be09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:56:08.838477Z",
     "iopub.status.busy": "2024-04-29T19:56:08.838061Z",
     "iopub.status.idle": "2024-04-29T19:56:08.859075Z",
     "shell.execute_reply": "2024-04-29T19:56:08.849026Z"
    },
    "papermill": {
     "duration": 0.041385,
     "end_time": "2024-04-29T19:56:08.868754",
     "exception": false,
     "start_time": "2024-04-29T19:56:08.827369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, logging_steps=100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for token_ids, attention_mask, features, score in train_dataloader:\n",
    "\n",
    "        output = model(token_ids.to(device), \n",
    "                        attention_mask.to(device), \n",
    "                        features.to(device))\n",
    "        loss = criterion(output, score.to(device)).float()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_scores = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for token_ids, attention_mask, features, score in dataloader:\n",
    "            output = model(token_ids.to(device), \n",
    "                           attention_mask.to(device), \n",
    "                           features.to(device))\n",
    "\n",
    "            loss = criterion(output, score.to(device))\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            all_scores.extend(score.cpu().numpy())\n",
    "            predictions.extend(output.cpu().numpy())\n",
    "\n",
    "    return running_loss / len(dataloader), np.array(all_scores), np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f414a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:56:08.890557Z",
     "iopub.status.busy": "2024-04-29T19:56:08.889229Z",
     "iopub.status.idle": "2024-04-29T19:56:08.897229Z",
     "shell.execute_reply": "2024-04-29T19:56:08.896232Z"
    },
    "papermill": {
     "duration": 0.021742,
     "end_time": "2024-04-29T19:56:08.899891",
     "exception": false,
     "start_time": "2024-04-29T19:56:08.878149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0290b4df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:56:08.920650Z",
     "iopub.status.busy": "2024-04-29T19:56:08.919570Z",
     "iopub.status.idle": "2024-04-29T19:56:09.579548Z",
     "shell.execute_reply": "2024-04-29T19:56:09.577708Z"
    },
    "papermill": {
     "duration": 0.672656,
     "end_time": "2024-04-29T19:56:09.581910",
     "exception": true,
     "start_time": "2024-04-29T19:56:08.909254",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(),\n\u001b[1;32m      3\u001b[0m                               lr\u001b[38;5;241m=\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      5\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopper(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=hyperparameters['lr'])\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.1)\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=1e-3)\n",
    "\n",
    "train_losses, val_losses, val_kappa_scores = [], [], []\n",
    "\n",
    "hyperparameters['early_stopper'] = early_stopper.__dict__['patience']\n",
    "hyperparameters['optimizer'] = optimizer.__dict__\n",
    "hyperparameters['scheduler'] = scheduler.__dict__\n",
    "hyperparameters['model'] = dict(model.__dict__['_modules'])\n",
    "\n",
    "\n",
    "def logit_to_score(logit, min_score=1, max_score=6):\n",
    "    scores = np.clip(np.round(logit), min_score, max_score)\n",
    "    scores = np.dtype(np.int32).type(scores)\n",
    "    return\n",
    "\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed63396",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(hyperparameters['epochs']):\n",
    "    train_loss = train(model, optimizer, criterion, train_dataloader)\n",
    "    val_loss, val_scores, val_predictions = evaluate(\n",
    "        model, criterion, val_dataloader)\n",
    "\n",
    "    val_kappa = cohen_kappa_score(\n",
    "        logit_to_score(val_predictions), val_scores,\n",
    "        labels=[1, 2, 3, 4, 5, 6],\n",
    "        weights='quadratic')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_kappa_scores.append(val_kappa)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}, Val Kappa: {val_kappa}')\n",
    "    \n",
    "    if early_stopper.early_stop(val_losses[-1]):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb56458",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in test_df.itertuples():\n",
    "        token_ids = torch.tensor(row.input_ids).unsqueeze(0)\n",
    "        attention_mask = torch.tensor(row.attention_mask).unsqueeze(0)\n",
    "        features = torch.tensor([row[1:11]]).float()\n",
    "        output = model(token_ids.to(device), \n",
    "                       attention_mask.to(device), \n",
    "                       features.to(device))\n",
    "        test_predictions.append(output.cpu().numpy()[0][0])\n",
    "\n",
    "test_kappa = cohen_kappa_score(\n",
    "    logit_to_score(test_predictions), test_df['score'].values, weights='quadratic')\n",
    "\n",
    "print(f'Test Kappa: {test_kappa}')\n",
    "\n",
    "submit_df = pd.DataFrame({\n",
    "    'essay_id': test_df['essay_id'],\n",
    "    'prediction': logit_to_score(test_predictions)\n",
    "})\n",
    "submit_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 3937250,
     "sourceId": 7017419,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4904293,
     "sourceId": 8262511,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4904414,
     "sourceId": 8262926,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4607.770037,
   "end_time": "2024-04-29T19:56:13.029927",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-29T18:39:25.259890",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
