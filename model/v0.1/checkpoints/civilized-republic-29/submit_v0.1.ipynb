{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01213058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:39:28.568197Z",
     "iopub.status.busy": "2024-04-29T18:39:28.567481Z",
     "iopub.status.idle": "2024-04-29T18:39:41.470194Z",
     "shell.execute_reply": "2024-04-29T18:39:41.468849Z"
    },
    "papermill": {
     "duration": 12.914696,
     "end_time": "2024-04-29T18:39:41.473365",
     "exception": false,
     "start_time": "2024-04-29T18:39:28.558669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import punctuation, printable\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34836a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:39:41.488799Z",
     "iopub.status.busy": "2024-04-29T18:39:41.488130Z",
     "iopub.status.idle": "2024-04-29T18:40:24.446879Z",
     "shell.execute_reply": "2024-04-29T18:40:24.445194Z"
    },
    "papermill": {
     "duration": 42.970553,
     "end_time": "2024-04-29T18:40:24.450646",
     "exception": false,
     "start_time": "2024-04-29T18:39:41.480093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pyspellchecker-0.8.1-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.8.1\r\n"
     ]
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "copy_tree('/kaggle/input/spellchecker', '/kaggle/working/')\n",
    "\n",
    "!gzip '/kaggle/working/spellchecker/resources/en.json'\n",
    "\n",
    "!pip install '/kaggle/working/pyspellchecker-0.8.1-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728e82c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:40:24.469627Z",
     "iopub.status.busy": "2024-04-29T18:40:24.469062Z",
     "iopub.status.idle": "2024-04-29T18:40:24.733335Z",
     "shell.execute_reply": "2024-04-29T18:40:24.732288Z"
    },
    "papermill": {
     "duration": 0.277968,
     "end_time": "2024-04-29T18:40:24.736271",
     "exception": false,
     "start_time": "2024-04-29T18:40:24.458303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5ab10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:40:24.753004Z",
     "iopub.status.busy": "2024-04-29T18:40:24.752235Z",
     "iopub.status.idle": "2024-04-29T18:40:27.603649Z",
     "shell.execute_reply": "2024-04-29T18:40:27.602635Z"
    },
    "papermill": {
     "duration": 2.862703,
     "end_time": "2024-04-29T18:40:27.606347",
     "exception": false,
     "start_time": "2024-04-29T18:40:24.743644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17307, 3) (3, 2) (13125, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>bb4c434</td>\n",
       "      <td>People tend to use there cars so much, they ba...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>44e88b0</td>\n",
       "      <td>Imagine being a top scientist at NASA and Viki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0ba78ec</td>\n",
       "      <td>The face of Mars could not be created by alien...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>f96c287</td>\n",
       "      <td>Many people belive that the face on Mars was c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>317173f</td>\n",
       "      <td>Driverless Cars are coming soon or later? Peop...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "12696  bb4c434  People tend to use there cars so much, they ba...      3\n",
       "4625   44e88b0  Imagine being a top scientist at NASA and Viki...      3\n",
       "733    0ba78ec  The face of Mars could not be created by alien...      3\n",
       "16885  f96c287  Many people belive that the face on Mars was c...      3\n",
       "3334   317173f  Driverless Cars are coming soon or later? Peop...      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2\"\n",
    "train_data = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n",
    "extra_data = pd.read_csv('/kaggle/input/persaude-corpus-2/persuade_2.0_human_scores_demo_id_github.csv')\n",
    "\n",
    "extra_data = extra_data.rename(columns={'essay_id_comp': 'essay_id',\n",
    "                                        'holistic_essay_score': 'score'})\n",
    "extra_data = extra_data[['essay_id', 'full_text', 'score']]\n",
    "\n",
    "extra_data = extra_data[~extra_data['full_text'].isin(train_data['full_text'])]\n",
    "\n",
    "print(train_data.shape, test_data.shape, extra_data.shape)\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056028b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:40:27.623231Z",
     "iopub.status.busy": "2024-04-29T18:40:27.622489Z",
     "iopub.status.idle": "2024-04-29T19:54:52.083577Z",
     "shell.execute_reply": "2024-04-29T19:54:52.082065Z"
    },
    "papermill": {
     "duration": 4464.473005,
     "end_time": "2024-04-29T19:54:52.086844",
     "exception": false,
     "start_time": "2024-04-29T18:40:27.613839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_misspelled(words):\n",
    "    words = [word for word in words if word.strip()]\n",
    "\n",
    "    words = set(words) - {\"'s\", \"n't\"} - set(punctuation)\n",
    "\n",
    "    return spell.unknown(words)\n",
    "\n",
    "\n",
    "def get_sentences(text: str):\n",
    "    text = \"\".join(filter(lambda x: x in printable, text)).strip()\n",
    "    doc = nlp(text)\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = \"\".join(filter(lambda x: x in printable, text)).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_features(data_df: pd.DataFrame, output_dir='./output/data_features.csv', save=True):\n",
    "    # parse the text into paragraphs\n",
    "    data_df['paragraphs'] = data_df['full_text'].apply(lambda x: x.split(\"\\n\\n\"))\n",
    "    data_df['num_paragraphs'] = data_df['paragraphs'].apply(len)\n",
    "\n",
    "    data_df['full_text'] = data_df['full_text'].apply(preprocess_text)\n",
    "\n",
    "    # into sentences\n",
    "    data_df['sentences'] = data_df['full_text'].apply(get_sentences)\n",
    "    data_df['num_sentences'] = data_df['sentences'].apply(len)\n",
    "\n",
    "    # Create lists to hold the results\n",
    "    words = []\n",
    "    lemmas = []\n",
    "    pos = []\n",
    "    is_stop_word = []\n",
    "\n",
    "    # Process the texts in batches\n",
    "    for i, doc in enumerate(nlp.pipe(data_df['full_text'], batch_size=50)):\n",
    "        print(f\"Processing batch {i+1}/{len(data_df)}\", end=\"\\r\")\n",
    "\n",
    "        words.append([token.text for token in doc])\n",
    "        lemmas.append([token.lemma_ for token in doc])\n",
    "        pos.append([token.pos_ for token in doc])\n",
    "        is_stop_word.append([token.is_stop for token in doc])\n",
    "\n",
    "    data_df['words'] = words\n",
    "    data_df['lemma'] = lemmas\n",
    "    data_df['pos'] = pos\n",
    "    data_df['is_stop_word'] = is_stop_word\n",
    "\n",
    "    data_df['num_words'] = data_df['words'].apply(len)\n",
    "\n",
    "    data_df['num_conjunctions'] = data_df['pos'].apply(\n",
    "        lambda x: len([pos for pos in x if pos == 'CCONJ']))\n",
    "\n",
    "    data_df['num_distinct_words'] = data_df['lemma'].apply(\n",
    "        lambda x: len(set(x)))\n",
    "\n",
    "    data_df['num_misspell'] = data_df['lemma'].apply(count_misspelled)\n",
    "    data_df['num_misspell'] = data_df['num_misspell'].apply(len)\n",
    "\n",
    "    data_df['mean_word_len'] = data_df['lemma'].apply(lambda x: np.mean(\n",
    "        [len(word) for word in x if word.strip() and word not in punctuation]))\n",
    "\n",
    "    data_df['mean_sent_len'] = data_df['sentences'].apply(\n",
    "        lambda x: np.mean([len([token.text for token in nlp(sent)]) for sent in x]))\n",
    "\n",
    "    if save:\n",
    "        data_df.to_csv(output_dir, index=False)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "test_df = get_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994ebf90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:54:52.229725Z",
     "iopub.status.busy": "2024-04-29T19:54:52.229263Z",
     "iopub.status.idle": "2024-04-29T19:55:00.586385Z",
     "shell.execute_reply": "2024-04-29T19:55:00.585013Z"
    },
    "papermill": {
     "duration": 8.369653,
     "end_time": "2024-04-29T19:55:00.589811",
     "exception": false,
     "start_time": "2024-04-29T19:54:52.220158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_path = '/kaggle/input/essay-scoring-models/longformer-base-4096'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "embedder = AutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_features = ['num_paragraphs', 'num_words', 'num_conjunctions',\n",
    "                 'num_distinct_words', 'num_misspell',\n",
    "                 'mean_word_len', 'num_sentences', 'mean_sent_len']\n",
    "\n",
    "hyperparameters = {\n",
    "    'lr': 1e-4,\n",
    "    'dropout': 0.2,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 64,\n",
    "    'test_set': {\n",
    "        'total': len(test_df),\n",
    "    },\n",
    "    'linguistic_features': ling_features,\n",
    "    'accelator': str(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b10c44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:55:00.608360Z",
     "iopub.status.busy": "2024-04-29T19:55:00.606937Z",
     "iopub.status.idle": "2024-04-29T19:55:00.615131Z",
     "shell.execute_reply": "2024-04-29T19:55:00.614011Z"
    },
    "papermill": {
     "duration": 0.020115,
     "end_time": "2024-04-29T19:55:00.618152",
     "exception": false,
     "start_time": "2024-04-29T19:55:00.598037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ling_features = ['num_paragraphs', 'num_words', 'num_conjunctions',\n",
    "                 'num_distinct_words', 'num_misspell',\n",
    "                 'mean_word_len', 'num_sentences', 'mean_sent_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8c2f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:55:00.635595Z",
     "iopub.status.busy": "2024-04-29T19:55:00.634464Z",
     "iopub.status.idle": "2024-04-29T19:56:01.964353Z",
     "shell.execute_reply": "2024-04-29T19:56:01.963102Z"
    },
    "papermill": {
     "duration": 61.341732,
     "end_time": "2024-04-29T19:56:01.967305",
     "exception": false,
     "start_time": "2024-04-29T19:55:00.625573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3159259489.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['input_ids'] = train_tokenized['input_ids'].tolist()\n",
      "/tmp/ipykernel_18/3159259489.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['attention_mask'] = train_tokenized['attention_mask'].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560\n",
      "2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3159259489.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df['input_ids'] = val_tokenized['input_ids'].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560\n",
      "2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3159259489.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df['attention_mask'] = val_tokenized['attention_mask'].tolist()\n"
     ]
    }
   ],
   "source": [
    "test_tokenized = tokenizer(test_df['full_text'].tolist(),\n",
    "                           max_length=hyperparameters['max_seq_len'], \n",
    "                           padding='max_length', truncation=True, \n",
    "                           return_tensors=\"np\")\n",
    "\n",
    "test_df['input_ids'] = test_tokenized['input_ids'].tolist()\n",
    "test_df['attention_mask'] = test_tokenized['attention_mask'].tolist()\n",
    "\n",
    "print(len(test_df.sample(1).iloc[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba9dca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:56:02.174051Z",
     "iopub.status.busy": "2024-04-29T19:56:02.173044Z",
     "iopub.status.idle": "2024-04-29T19:56:08.815508Z",
     "shell.execute_reply": "2024-04-29T19:56:08.814072Z"
    },
    "papermill": {
     "duration": 6.656594,
     "end_time": "2024-04-29T19:56:08.818710",
     "exception": false,
     "start_time": "2024-04-29T19:56:02.162116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiFeaturesModel(torch.nn.Module):\n",
    "    def __init__(self, embedder,\n",
    "                 lf_input_size, lf_hidden_size=64,\n",
    "                 dropout=0.2):\n",
    "        super(MultiFeaturesModel, self).__init__()\n",
    "        # freeze\n",
    "        for param in embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.embedder = embedder\n",
    "        self.lf = torch.nn.Linear(lf_input_size,lf_hidden_size)\n",
    "        self.fc = torch.nn.Linear(lf_hidden_size + embedder.config.hidden_size, 128)\n",
    "        self.regressor = torch.nn.Linear(128, 1)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "    \n",
    "    def config(self):\n",
    "        return {\n",
    "            'embedder': self.embedder.config,\n",
    "            'lf': {\n",
    "                'input_size': self.lf.in_features,\n",
    "                'hidden_size': self.lf.out_features\n",
    "            },\n",
    "            'fc': {\n",
    "                'input_size': self.fc.in_features,\n",
    "                'hidden_size': self.fc.out_features\n",
    "            },\n",
    "            'regressor': {\n",
    "                'input_size': self.regressor.in_features,\n",
    "                'output_size': self.regressor.out_features\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def forward(self, token_ids, attention_mask, ling_features):\n",
    "        embedded = self.embedder(token_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        if self.training:\n",
    "            embedded = self.dropout(embedded)\n",
    "            \n",
    "        ling_features = F.leaky_relu(self.lf(ling_features))\n",
    "        if self.training:\n",
    "            ling_features = self.dropout(ling_features)\n",
    "            \n",
    "        features = torch.cat((embedded, ling_features), dim=1)\n",
    "        features = F.leaky_relu(self.fc(features))\n",
    "        if self.training:\n",
    "            features = self.dropout(features)\n",
    "            \n",
    "        score = self.regressor(features)\n",
    "        return score\n",
    "\n",
    "\n",
    "model = MultiFeaturesModel(embedder, len(ling_features),\n",
    "                           128,\n",
    "                           hyperparameters['dropout'])\n",
    "\n",
    "model.load_state_dict(torch.load('/kaggle/input/essay-scoring-models/checkpoints/multi_features_longformer-base-4096_2024Y-05m-04d_model.pth',\n",
    "                                 map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_to_score(logit, min_score=1, max_score=6):\n",
    "    scores = torch.clamp(torch.round(logit), min_score, max_score)\n",
    "    scores = scores.long()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb56458",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in test_df.itertuples():\n",
    "        token_ids = torch.tensor(row.input_ids).unsqueeze(0)\n",
    "        attention_mask = torch.tensor(row.attention_mask).unsqueeze(0)\n",
    "        features = torch.tensor([row[1:11]]).float()\n",
    "        output = model(token_ids.to(device), \n",
    "                       attention_mask.to(device), \n",
    "                       features.to(device))\n",
    "        test_predictions.append(output.cpu().numpy()[0][0])\n",
    "\n",
    "submit_df = pd.DataFrame({\n",
    "    'essay_id': test_df['essay_id'],\n",
    "    'prediction': logit_to_score(test_predictions)\n",
    "})\n",
    "submit_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 3937250,
     "sourceId": 7017419,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4904293,
     "sourceId": 8262511,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4904414,
     "sourceId": 8262926,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4607.770037,
   "end_time": "2024-04-29T19:56:13.029927",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-29T18:39:25.259890",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
